{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://claude.ai/chat/ea276ca5-a568-457f-a70b-94febb7e4b6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables and initialize client\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_KEY\"))\n",
    "\n",
    "class DataAnalysisGPT:\n",
    "    def __init__(self):\n",
    "        self.client = client\n",
    "    \n",
    "    def generate_sql_query(self, description):\n",
    "        \"\"\"Generates SQL queries from natural language descriptions.\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a SQL expert. Generate SQL queries based on natural language descriptions.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Generate a SQL query for: {description}\"}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def explain_code(self, code):\n",
    "        \"\"\"Explains complex data analysis code.\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a Python data analysis expert. Explain code in detail.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Explain this code:\\n{code}\"}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def suggest_visualizations(self, df_info):\n",
    "        \"\"\"Suggests appropriate visualizations based on data characteristics.\"\"\"\n",
    "        df_description = f\"Columns and their types:\\n{df_info}\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a data visualization expert. Suggest appropriate charts and plots.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Suggest visualizations for this dataset:\\n{df_description}\"}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def generate_data_cleaning_code(self, df_head, issues):\n",
    "        \"\"\"Generates code for data cleaning based on identified issues.\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a data cleaning expert. Generate Python code for data cleaning.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Generate code to clean this data with these issues:\\nData:\\n{df_head}\\nIssues:\\n{issues}\"}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def interpret_statistical_results(self, results):\n",
    "        \"\"\"Interprets statistical analysis results in plain language.\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a statistics expert. Interpret statistical results in plain language.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Interpret these statistical results:\\n{results}\"}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def generate_eda_code(self, df_info):\n",
    "        \"\"\"Generates exploratory data analysis code.\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an EDA expert. Generate Python code for exploratory data analysis.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Generate EDA code for this dataset:\\n{df_info}\"}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "analyzer = DataAnalysisGPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Query:  Certainly! Assuming you have a sales table named `sales` with at least the following columns: `category_id`, `sale_date`, and `amount`, the SQL query to find the average sales by product category for the last quarter would look something like this:\n",
      "\n",
      "```sql\n",
      "SELECT \n",
      "    category_id, \n",
      "    AVG(amount) AS average_sales\n",
      "FROM \n",
      "    sales\n",
      "WHERE \n",
      "    sale_date >= DATE_TRUNC('quarter', CURRENT_DATE - INTERVAL '1 quarter') \n",
      "    AND sale_date < DATE_TRUNC('quarter', CURRENT_DATE)\n",
      "GROUP BY \n",
      "    category_id;\n",
      "```\n",
      "\n",
      "This query does the following:\n",
      "- Selects the `category_id` and calculates the average sales (`AVG(amount)`) for each category.\n",
      "- Filters the sales to include only those that occurred in the last quarter.\n",
      "- Groups the results by `category_id` to get the average sales per category.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Generate SQL Query\n",
    "sql_description = \"Find the average sales by product category for the last quarter\"\n",
    "sql_query = analyzer.generate_sql_query(sql_description)\n",
    "\n",
    "print(\"SQL Query: \", sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization Suggestions:  For the dataset you've described, here are some suitable visualizations based on the columns and their types:\n",
      "\n",
      "1. **Time Series Line Chart**:\n",
      "   - **Purpose**: To visualize trends in sales over time.\n",
      "   - **Details**: Use the `date` column on the x-axis and the `sales` column on the y-axis. This will help you identify any trends, seasonality, or patterns in sales over specific periods.\n",
      "\n",
      "2. **Bar Chart**:\n",
      "   - **Purpose**: To compare total sales by `category`.\n",
      "   - **Details**: Use `category` on the x-axis and the sum of `sales` on the y-axis. This will provide a clear comparison of sales across different categories.\n",
      "\n",
      "3. **Box Plot**:\n",
      "   - **Purpose**: To analyze the distribution of `sales` across different `categories`.\n",
      "   - **Details**: Use `category` as the x-axis and `sales` as the y-axis. This visualization will show you the median, quartiles, and potential outliers in sales within each category.\n",
      "\n",
      "4. **Histogram**:\n",
      "   - **Purpose**: To visualize the distribution of `satisfaction_score`.\n",
      "   - **Details**: A histogram can illustrate how customer satisfaction scores are distributed, allowing you to identify any peaks or gaps in satisfaction.\n",
      "\n",
      "5. **Scatter Plot**:\n",
      "   - **Purpose**: To investigate the relationship between `satisfaction_score` and `sales`.\n",
      "   - **Details**: Use `satisfaction_score` on the x-axis and `sales` on the y-axis. This can help visualize any correlation between customer satisfaction and sales performance.\n",
      "\n",
      "6. **Heatmap**:\n",
      "   - **Purpose**: To explore sales patterns over time by category.\n",
      "   - **Details**: Create a heatmap with `date` on one axis (potentially months or weeks aggregated) and `category` on the other, with the cell colors representing total sales volume. This can highlight periods when specific categories performed well.\n",
      "\n",
      "7. **Pie Chart or Donut Chart**:\n",
      "   - **Purpose**: To show the market share of total sales by category.\n",
      "   - **Details**: This can provide a quick visual representation of how much each category contributes to overall sales. However, use this sparingly as pie charts can be harder to interpret accurately.\n",
      "\n",
      "8. **Customer Segmentation Plot (if applicable)**:\n",
      "   - **Purpose**: If you have a way to categorize customers or if you want to understand customer behavior better.\n",
      "   - **Details**: You could create a scatter plot (e.g., using clustering techniques) to see how different segments of customers interact with sales and satisfaction scores.\n",
      "\n",
      "Each of these visualizations serves to highlight different aspects of your dataset and will help in drawing insights regarding sales trends, customer satisfaction, and category performance.\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Get visualization suggestions\n",
    "df_info = \"\"\"\n",
    "columns:\n",
    "- sales (float64)\n",
    "- date (datetime64)\n",
    "- category (object)\n",
    "- customer_id (int64)\n",
    "- satisfaction_score (int64)\n",
    "\"\"\"\n",
    "viz_suggestions = analyzer.suggest_visualizations(df_info)\n",
    "\n",
    "print(\"Visualization Suggestions: \", viz_suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning Code:  To clean the data you provided, we will address the missing values in the `age` and `income` columns. We can handle missing values in several ways; common strategies include filling them with the mean, median, or mode of the column, or dropping rows with missing values. In this example, I will show how to fill missing values with the mean for both columns. \n",
      "\n",
      "Here's the Python code using pandas for data cleaning:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# Sample data\n",
      "data = {\n",
      "    'age': [25, np.nan, 35],\n",
      "    'income': [50000, 60000, np.nan],\n",
      "    'education': ['Bachelor', 'Master', 'PhD'],\n",
      "    'missing_values': [np.nan, 'Yes', 'No']\n",
      "}\n",
      "\n",
      "# Create a DataFrame\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Display the original DataFrame\n",
      "print(\"Original DataFrame:\")\n",
      "print(df)\n",
      "\n",
      "# Fill missing values in 'age' with the mean of the column\n",
      "df['age'].fillna(df['age'].mean(), inplace=True)\n",
      "\n",
      "# Fill missing values in 'income' with the mean of the column\n",
      "df['income'].fillna(df['income'].mean(), inplace=True)\n",
      "\n",
      "# Optionally, handle missing values in other columns (e.g., 'missing_values')\n",
      "# Here we will fill NaN with 'No' as a default value\n",
      "df['missing_values'].fillna('No', inplace=True)\n",
      "\n",
      "# Display the cleaned DataFrame\n",
      "print(\"\\nCleaned DataFrame:\")\n",
      "print(df)\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Import Libraries**: We import pandas for data manipulation and numpy for handling NaN values.\n",
      "2. **Create DataFrame**: We create a DataFrame based on the provided data.\n",
      "3. **Fill Missing Values**: \n",
      "    - The `fillna` method is used to replace NaN values in the 'age' and 'income' columns with their respective means.\n",
      "    - For the `missing_values` column, we fill NaN with 'No' as a reasonable default.\n",
      "4. **Display**: The original and cleaned DataFrames are printed to see the changes.\n",
      "\n",
      "When you run this code, missing values will be appropriately filled and the DataFrame will be cleaned.\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Generate data cleaning code\n",
    "sample_data = \"\"\"\n",
    "   age  income education missing_values\n",
    "0  25   50000  Bachelor         NaN\n",
    "1  NaN  60000  Master          Yes\n",
    "2  35   NaN    PhD             No\n",
    "\"\"\"\n",
    "issues = \"Contains missing values in age and income columns, needs to handle NaN values\"\n",
    "cleaning_code = analyzer.generate_data_cleaning_code(sample_data, issues)\n",
    "\n",
    "print(\"Data Cleaning Code: \", cleaning_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
