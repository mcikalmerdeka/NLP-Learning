{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://claude.ai/chat/ea276ca5-a568-457f-a70b-94febb7e4b6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "\n",
    "class ClaudeAnalysis:\n",
    "    def __init__(self, model=\"claude-3-sonnet-20240229\"):\n",
    "        \"\"\"\n",
    "        Initialize the ClaudeAnalysis class.\n",
    "        Args:\n",
    "            model (str): The Claude model to use. Options:\n",
    "                        - \"claude-3-haiku-20240307\" (fastest)\n",
    "                        - \"claude-3-sonnet-20240229\" (balanced)\n",
    "                        - \"claude-3-opus-20240229\" (most capable)\n",
    "        \"\"\"\n",
    "        load_dotenv()\n",
    "        self.client = Anthropic(api_key=os.environ.get(\"ANTHROPIC_KEY\"))\n",
    "        self.model = model\n",
    "    \n",
    "    def generate_sql_query(self, description):\n",
    "        \"\"\"Generates SQL queries from natural language descriptions.\"\"\"\n",
    "        message = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            system=\"You are a SQL expert. Generate SQL queries based on natural language descriptions. Include comments explaining the query.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Generate a SQL query for: {description}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    \n",
    "    def explain_code(self, code):\n",
    "        \"\"\"Explains complex data analysis code.\"\"\"\n",
    "        message = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            system=\"You are a Python data analysis expert. Explain code in detail, including best practices and potential improvements.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Explain this code:\\n{code}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    \n",
    "    def suggest_visualizations(self, df_info):\n",
    "        \"\"\"Suggests appropriate visualizations based on data characteristics.\"\"\"\n",
    "        message = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            system=\"You are a data visualization expert. Suggest appropriate charts and plots based on data types and analysis goals.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Suggest visualizations for this dataset:\\n{df_info}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    \n",
    "    def generate_data_cleaning_code(self, df_head, issues):\n",
    "        \"\"\"Generates code for data cleaning based on identified issues.\"\"\"\n",
    "        message = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            system=\"You are a data cleaning expert. Generate Python code for data cleaning, including error handling and validation.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Generate code to clean this data with these issues:\\nData:\\n{df_head}\\nIssues:\\n{issues}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    \n",
    "    def interpret_statistical_results(self, results):\n",
    "        \"\"\"Interprets statistical analysis results in plain language.\"\"\"\n",
    "        message = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            system=\"You are a statistics expert. Interpret statistical results in plain language, highlighting key findings and implications.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Interpret these statistical results:\\n{results}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    \n",
    "    def generate_eda_code(self, df_info):\n",
    "        \"\"\"Generates exploratory data analysis code.\"\"\"\n",
    "        message = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            system=\"You are a Python data analysis expert. Generate comprehensive Python code for exploratory data analysis.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Generate EDA code for this dataset:\\n{df_info}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    \n",
    "    def analyze_visualization(self, plt_figure, specific_questions=None):\n",
    "        \"\"\"Analyzes a visualization and provides insights.\"\"\"\n",
    "        # Save plot to buffer\n",
    "        buffer = io.BytesIO()\n",
    "        plt_figure.savefig(buffer, format='png')\n",
    "        buffer.seek(0)\n",
    "        \n",
    "        # Convert to base64\n",
    "        image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        if specific_questions is None:\n",
    "            specific_questions = \"What are the main insights from this visualization? Include specific numbers and patterns.\"\n",
    "            \n",
    "        message = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": specific_questions\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/png\",\n",
    "                            \"data\": image_base64\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        # Clean up\n",
    "        buffer.close()\n",
    "        \n",
    "        return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Initialize the analyzer\n",
    "analyzer = ClaudeAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated SQL Query:\n",
      "-- Find the average sales by product category for the last quarter\n",
      "SELECT \n",
      "    pc.CategoryName,\n",
      "    AVG(od.Quantity * od.UnitPrice) AS AvgSales\n",
      "FROM\n",
      "    OrderDetails od\n",
      "    JOIN Orders o ON od.OrderID = o.OrderID\n",
      "    JOIN Products p ON od.ProductID = p.ProductID\n",
      "    JOIN ProductCategories pc ON p.CategoryID = pc.CategoryID\n",
      "WHERE\n",
      "    o.OrderDate >= DATE_SUB(NOW(), INTERVAL 3 MONTH) -- Orders from the last quarter\n",
      "GROUP BY\n",
      "    pc.CategoryName;\n",
      "\n",
      "-- Explanation:\n",
      "-- 1. The query joins multiple tables (OrderDetails, Orders, Products, and ProductCategories) to access the required data.\n",
      "-- 2. The WHERE clause filters orders from the last quarter using the DATE_SUB function.\n",
      "-- 3. The AVG aggregate function calculates the average sales (Quantity * UnitPrice) for each product category.\n",
      "-- 4. The GROUP BY clause groups the results by product category name.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Generate SQL Query\n",
    "sql_description = \"Find the average sales by product category for the last quarter\"\n",
    "sql_query = analyzer.generate_sql_query(sql_description)\n",
    "print(\"\\nGenerated SQL Query:\")\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualization Suggestions:\n",
      "Based on the provided dataset, here are some appropriate data visualization suggestions:\n",
      "\n",
      "1. **Line Chart or Area Chart**: To visualize the trend of sales over time, a line chart or an area chart could be used, with the x-axis representing the date and the y-axis representing the sales.\n",
      "\n",
      "2. **Bar Chart or Column Chart**: To compare sales across different categories, a bar chart or a column chart could be used, with the x-axis representing the categories and the y-axis representing the sales.\n",
      "\n",
      "3. **Scatter Plot**: To analyze the relationship between sales and satisfaction_score, a scatter plot could be used, with the x-axis representing the satisfaction_score and the y-axis representing the sales. You could also color-code or use different markers to distinguish different categories.\n",
      "\n",
      "4. **Box Plot or Violin Plot**: To examine the distribution of sales or satisfaction_score across different categories, a box plot or a violin plot could be used, with the x-axis representing the categories and the y-axis representing the sales or satisfaction_score.\n",
      "\n",
      "5. **Histogram**: To visualize the distribution of sales or satisfaction_score, a histogram could be used, with the x-axis representing the range of values and the y-axis representing the frequency or count.\n",
      "\n",
      "6. **Pie Chart or Donut Chart**: To show the proportion of sales or customer_id across different categories, a pie chart or a donut chart could be used, with each slice representing a category and its size proportional to the corresponding value.\n",
      "\n",
      "7. **Heatmap**: If you want to analyze the relationship between multiple variables, such as sales, satisfaction_score, and category, a heatmap could be used, with different colors representing the intensity of the values.\n",
      "\n",
      "8. **Bubble Chart**: If you want to visualize the relationship between three variables, such as sales, satisfaction_score, and category, a bubble chart could be used, where the size of the bubbles represents one variable, and the x and y coordinates represent the other two variables.\n",
      "\n",
      "It's important to note that the choice of visualization should be based on the specific analysis goals and data types. Additionally, you may need to perform data preprocessing, such as handling missing values, outliers, or data transformations, before creating the visualizations.\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Get visualization suggestions\n",
    "df_info = \"\"\"\n",
    "columns:\n",
    "- sales (float64)\n",
    "- date (datetime64)\n",
    "- category (object)\n",
    "- customer_id (int64)\n",
    "- satisfaction_score (int64)\n",
    "\"\"\"\n",
    "viz_suggestions = analyzer.suggest_visualizations(df_info)\n",
    "print(\"\\nVisualization Suggestions:\")\n",
    "print(viz_suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Cleaning Code:\n",
      "Here's some Python code to clean the given data with error handling and validation:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the data\n",
      "data = pd.DataFrame({\n",
      "    'age': [25, None, 35],\n",
      "    'income': [50000, 60000, None],\n",
      "    'education': ['Bachelor', 'Master', 'PhD'],\n",
      "    'missing_values': ['NaN', 'Yes', 'No']\n",
      "})\n",
      "\n",
      "# Function to handle missing values\n",
      "def handle_missing_values(df):\n",
      "    # Drop rows with missing values in 'age' and 'income' columns\n",
      "    df.dropna(subset=['age', 'income'], inplace=True)\n",
      "    \n",
      "    # Fill NaN values in 'missing_values' column with 'Unknown'\n",
      "    df['missing_values'].fillna('Unknown', inplace=True)\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Function to validate age and income values\n",
      "def validate_values(df):\n",
      "    # Check for valid age range\n",
      "    age_mask = (df['age'] >= 18) & (df['age'] <= 100)\n",
      "    if not age_mask.all():\n",
      "        print(\"Warning: Some age values are outside the valid range (18-100).\")\n",
      "    \n",
      "    # Check for valid income range\n",
      "    income_mask = (df['income'] >= 0)\n",
      "    if not income_mask.all():\n",
      "        print(\"Warning: Some income values are negative.\")\n",
      "    \n",
      "    return df\n",
      "\n",
      "# Clean the data\n",
      "cleaned_data = handle_missing_values(data)\n",
      "cleaned_data = validate_values(cleaned_data)\n",
      "\n",
      "# Print the cleaned data\n",
      "print(cleaned_data)\n",
      "```\n",
      "\n",
      "This code does the following:\n",
      "\n",
      "1. Loads the data into a pandas DataFrame.\n",
      "2. Defines a function `handle_missing_values` that drops rows with missing values in the 'age' and 'income' columns and fills NaN values in the 'missing_values' column with 'Unknown'.\n",
      "3. Defines a function `validate_values` that checks for valid age range (18-100) and valid income range (non-negative).\n",
      "4. Calls the `handle_missing_values` and `validate_values` functions to clean and validate the data.\n",
      "5. Prints the cleaned data.\n",
      "\n",
      "The output will be:\n",
      "\n",
      "```\n",
      "   age  income education missing_values\n",
      "0   25   50000  Bachelor            NaN\n",
      "```\n",
      "\n",
      "Note that the row with missing values in both 'age' and 'income' columns is dropped, and a warning is printed for the missing value in the 'missing_values' column, which is filled with 'Unknown'.\n",
      "\n",
      "If there are any age or income values outside the valid range, a warning will be printed as well.\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Generate data cleaning code\n",
    "sample_data = \"\"\"\n",
    "   age  income education missing_values\n",
    "0  25   50000  Bachelor         NaN\n",
    "1  NaN  60000  Master          Yes\n",
    "2  35   NaN    PhD             No\n",
    "\"\"\"\n",
    "issues = \"Contains missing values in age and income columns, needs to handle NaN values\"\n",
    "cleaning_code = analyzer.generate_data_cleaning_code(sample_data, issues)\n",
    "print(\"\\nData Cleaning Code:\")\n",
    "print(cleaning_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
